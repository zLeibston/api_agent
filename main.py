import os
import json
import datetime
from typing import cast, List, Dict, Any, Optional
from openai import OpenAI
from openai.types.chat import (
    ChatCompletionMessageParam, 
    ChatCompletionToolParam, 
    ChatCompletionMessageToolCall
)
from dotenv import load_dotenv
from utils.find_root_dir import get_project_root
from utils.json_clean import parse_json_from_llm 



class AgentMemory:
    def __init__(self, file_path: str):
        self.file_path = file_path
        self._ensure_file_validity() # å¯åŠ¨æ—¶è‡ªæ£€

    def _ensure_file_validity(self):
        """ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”æ˜¯åˆæ³•çš„ JSON,å¦åˆ™é‡ç½®"""
        if not os.path.exists(self.file_path):
            self._reset_memory()
            return
        
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•è¯»å–ï¼Œçœ‹æ˜¯ä¸æ˜¯åçš„
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if not content: # å¦‚æœæ˜¯ç©ºæ–‡ä»¶
                    raise ValueError("File is empty")
                json.loads(content) # å°è¯•è§£æ
        except (json.JSONDecodeError, ValueError):
            print(f"âš ï¸ è­¦å‘Šï¼šè®°å¿†æ–‡ä»¶ {self.file_path} æŸåæˆ–ä¸ºç©ºï¼Œå·²é‡ç½®ä¸º []ã€‚")
            self._reset_memory()

    def _reset_memory(self):
        """é‡ç½®è®°å¿†æ–‡ä»¶"""
        with open(self.file_path, 'w', encoding='utf-8') as f:
            json.dump([], f)

    def read(self, query: str = "") -> str:
        self._ensure_file_validity() # è¯»ä¹‹å‰å†æ£€æŸ¥ä¸€æ¬¡
        with open(self.file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return json.dumps(data, ensure_ascii=False)

    def write(self, content: str) -> str:
        self._ensure_file_validity() # å†™ä¹‹å‰å†æ£€æŸ¥ä¸€æ¬¡
        
        # è¯»å–ç°æœ‰æ•°æ®
        with open(self.file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # è¿½åŠ æ–°æ•°æ®
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        data.append({"time": timestamp, "content": content})
        
        # é‡æ–°å†™å…¥
        with open(self.file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        return f"å·²è®°å½•: {content}"

class Agent:
    def __init__(self, api_key: str, base_url: str, model_name: str, memory_path: str):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model_name = model_name
        self.memory = AgentMemory(memory_path) # æ‹¥æœ‰ä¸€ä¸ªè®°å¿†æ¨¡å—
        self.max_history = 5  # ã€æ–°å¢ã€‘åªä¿ç•™æœ€è¿‘ 5 è½®å¯¹è¯
        
        # ä¸Šä¸‹æ–‡å†å²
        self.messages: List[ChatCompletionMessageParam] = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰é•¿æœŸè®°å¿†çš„ç ”ç©¶å‹Agentã€‚"}
        ]
        
        # æ³¨å†Œå·¥å…·
        self.tools_schema = self._get_tools_schema()
        self.available_functions = {
            "manage_memory": self._tool_manage_memory, # æŠŠå·¥å…·ç»‘å®šåˆ°ç±»æ–¹æ³•ä¸Š
            "get_time": self._tool_get_time
        }

    def _get_tools_schema(self) -> List[ChatCompletionToolParam]:
        return [
            {
                "type": "function",
                "function": {
                    "name": "manage_memory",
                    "description": "è®°å¿†ç®¡ç†ã€‚å¦‚æœä½ è§‰å¾—æœ‰äº›ä¿¡æ¯ä½ åº”è¯¥çŸ¥é“ä½†å´ä¸çŸ¥é“ï¼Œä»–æœ‰å¯èƒ½åœ¨ä½ çš„è®°å¿†å­˜å‚¨é‡Œé¢ï¼Œè¯•è¯•åœ¨è®°å¿†ä¸­æ‰¾æ‰¾ã€‚å¦‚æœä½ è§‰å¾—æœ‰é‡è¦ä¿¡æ¯ï¼Œä¹Ÿè¯·å†™å…¥è®°å¿†ä¸­ã€‚action='read'è¯»å–ç›¸å…³è®°å¿†ï¼Œaction='write'å†™å…¥é‡è¦ä¿¡æ¯ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "action": {"type": "string", "enum": ["read", "write"]},
                            "content": {"type": "string", "description": "å†™å…¥çš„å†…å®¹æˆ–è¯»å–çš„æŸ¥è¯¢è¯"}
                        },
                        "required": ["action"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_time",
                    "description": "è·å–å½“å‰æ—¶é—´",
                    "parameters": {"type": "object", "properties": {}}
                }
            }
        ]
    
    def _manage_history(self):
        """
        åªä¿ç•™æœ€è¿‘çš„ max_history è½®å¯¹è¯ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡è¿‡é•¿
        """
        if len(self.messages) > self.max_history * 2 + 1: # *2 æ˜¯å› ä¸º(User+Assistant)æˆå¯¹ï¼Œ+1æ˜¯System
      
            system_msg = self.messages[0]
           
            recent_msgs = self.messages[-(self.max_history * 2):]
           
            self.messages = [system_msg] + recent_msgs
           

    # --- å·¥å…·å…·ä½“å®ç° ---
    def _tool_manage_memory(self, args: Dict[str, Any]):
        action = args.get("action")
        content = args.get("content", "")
        if action == "write":
            return self.memory.write(content)
        elif action == "read":
            return self.memory.read(content) # è¿™é‡Œä¼ å…¥ content ä½œä¸º query
        return "æœªçŸ¥æ“ä½œ"

    def _tool_get_time(self, args):
        return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # --- æ ¸å¿ƒæ€è€ƒæ­¥ (Step) ---
    def chat(self, user_input: str) -> str:
        """
        æ‰§è¡Œä¸€æ¬¡å¯¹è¯äº¤äº’ã€‚
        è¿™æŠŠåŸæ¥çš„å¤§ while å¾ªç¯æ‹†è§£æˆäº†å•æ¬¡å‡½æ•°è°ƒç”¨ï¼Œæ–¹ä¾¿è¯„æµ‹ã€‚
        """
        self._manage_history()

        self.messages.append({"role": "user", "content": user_input})
        
        # 1. æ€è€ƒ
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=self.messages,
            tools=self.tools_schema,
            tool_choice="auto"
        )
        response_msg = response.choices[0].message
        
        # 2. å†³ç­–ä¸å·¥å…·è°ƒç”¨
        if response_msg.tool_calls:
            self.messages.append(cast(ChatCompletionMessageParam, response_msg.model_dump()))
            
            for tool_call in response_msg.tool_calls:
                tool_call = cast(ChatCompletionMessageToolCall, tool_call)
                func_name = tool_call.function.name
                func_args = parse_json_from_llm(tool_call.function.arguments)

                
                
                print(f"âš™ï¸ è°ƒç”¨å·¥å…·: {func_name} | å‚æ•°: {func_args}")
                
                # æ‰§è¡Œ
                func_result = self.available_functions[func_name](func_args)
                
                self.messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "content": str(func_result)
                })
            
            # 3. æ‹¿åˆ°å·¥å…·ç»“æœåçš„äºŒæ¬¡å›å¤
            final_res = self.client.chat.completions.create(
                model=self.model_name,
                messages=self.messages
            )
            reply = final_res.choices[0].message.content
        else:
            reply = response_msg.content

        # è®°å½•åŠ©æ‰‹å›å¤
        if reply:
            self.messages.append({"role": "assistant", "content": reply})
        
        return str(reply)
    


    


if __name__ == "__main__":
    load_dotenv()
    # é…ç½®
    API_KEY = os.getenv("DEEPSEEK_API_KEY")

    if not API_KEY:
        raise ValueError("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ° API Keyï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠå˜é‡åæ˜¯å¦æ­£ç¡®ã€‚")

    BASE_URL = os.getenv("DEEPSEEK_URL")

    if not BASE_URL:
        raise ValueError("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ° URLï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠå˜é‡åæ˜¯å¦æ­£ç¡®ã€‚")
    
  
    project_root_dir = get_project_root()
    memory_path = os.path.join(project_root_dir, "memory", "main_memory.json")

   
    my_agent = Agent(
        api_key=API_KEY, 
        base_url=BASE_URL, 
        model_name="deepseek-chat",
        memory_path=memory_path
    )

    print(" Agent å·²å¯åŠ¨...")
    while True:
        q = input("\nğŸ‘¤ ä½ : ")
        if q.lower() in ['q', 'exit']: break
        
        ans = my_agent.chat(q)
        print(f"ğŸ¤– Agent: {ans}")